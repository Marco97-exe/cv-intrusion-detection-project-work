{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Intrusion Detection Computer Vision System"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The given tasks are the following:\n",
    "- For each frame of an input video, the system needs to display the found blobs (either by coloring them on a black background or by showing the countours on top of the original video) and produce a textual output listing the found blobs and their meaningful features.\n",
    "- The system is required to discriminate between a present blob and a false one originated by the removal of an object in the background.\n",
    "\n",
    "The proposed solution uses the developed library `intrusiondetection` and this notebook shows the step-by-step operations computed to achieve the final outputs alongside considerations over the made choices. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "from intrusiondetection.parameters import ParameterList\n",
    "from intrusiondetection.utility import distance_euclidean\n",
    "from intrusiondetection.model import MorphOp, MorphOpsSet, Video, Background\n",
    "\n",
    "# Only for jupyter notebook visualization\n",
    "%matplotlib inline \n",
    "\n",
    "video = Video(\"rilevamento-intrusioni-video.avi\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1. Considerations\n",
    "\n",
    "The given video presents the following characteristics:\n",
    "- 12 fps\n",
    "- ~41s\n",
    "- 320x240 pixels\n",
    "- 8 bit/pixel (256 gray levels)\n",
    "\n",
    "Osservando il contenuto si possono notare i seguenti dettagli:\n",
    "- Il video presenta del rumore, perciò sarà necessario utilizzare degli operatori di bin morph per migliorare il risultato ottenuto\n",
    "- A primo impatto si osserva che ci sono dei cambi di luce consistenti nel corso del video: per questo motivo si intuisce che adoperare un background dinamico possa migliorare il risultato, la tecnica è utilizzabile grazie anche al numero di FPS non estremamente ridotto.\n",
    "- La persona nel corso del video cambia la propria velocità, per questo motivo sarà necessario ottimizzare l'adaptation rate del background"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Background Estimation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1. Initial Background\n",
    "\n",
    "To estimate a good background for the scene, it's necessary to perform an interpolation between some chosen frames of the video.\n",
    "\n",
    "- The different interpolation functions considered are `np.mean` and `np.median`.\n",
    "- The amount of initial frames is tuned based on a tradeoff between the smallest and most stable number, therefore the considered values are 60, 80, 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "video_input_path = \"rilevamento-intrusioni-video.avi\"\n",
    "\n",
    "bg1 = Background(video_input_path, np.median, 60)\n",
    "bg2 = Background(video_input_path, np.median, 80)\n",
    "background = Background(video_input_path, np.median, 100)\n",
    "bg4 = Background(video_input_path, np.mean, 60)\n",
    "bg5 = Background(video_input_path, np.mean, 80)\n",
    "bg6 = Background(video_input_path, np.mean, 100)\n",
    "\n",
    "\n",
    "plt.figure(figsize=(20, 10))\n",
    "plt.subplot(1, 3, 1)\n",
    "bg1.show('image', show=False)\n",
    "plt.subplot(1, 3, 2)\n",
    "bg2.show('image', show=False)\n",
    "plt.subplot(1, 3, 3)\n",
    "background.show('image', show=False)\n",
    "plt.show()\n",
    "\n",
    "plt.figure(figsize=(20, 10))\n",
    "plt.subplot(1, 3, 1)\n",
    "bg4.show('image', show=False)\n",
    "plt.subplot(1, 3, 2)\n",
    "bg5.show('image', show=False)\n",
    "plt.subplot(1, 3, 3)\n",
    "bg6.show('image', show=False)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TODO Considerations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2. Background update\n",
    "The two main approaches to obtain a dynamic background are `blind` and `selective`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following section shows an example of a blind background computed using an adaption rate of `0.1`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "blind_backgrounds = video.process_backgrounds('blind', background, 0.1)\n",
    "curr_background = blind_backgrounds[300]\n",
    "curr_background.show('image')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the selective approach, there are also threshold and distance function parameters to compute the subtraction between the frame and the background, furthermore, some binary morphology operators are applied to get rid of most of the noise."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "selective_backgrounds = video.process_backgrounds('selective', background, 0.1, 37, distance_euclidean, MorphOpsSet(\n",
    "    MorphOp(cv2.MORPH_CLOSE, (3,3), iterations=1),\n",
    "    MorphOp(cv2.MORPH_OPEN, (3,3), iterations=2), \n",
    "    MorphOp(cv2.MORPH_DILATE, (25,10)), \n",
    "    MorphOp(cv2.MORPH_ERODE, (15,5))\n",
    "))\n",
    "curr_background = selective_backgrounds[400]\n",
    "curr_background.show(['subtraction', 'mask_raw', 'mask_refined', 'image'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A selective background clearly obtains better results, it is therefore the preferred method."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Change Detection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1. Background Subtraction\n",
    "\n",
    "To perform the change detection the first step is to subtract the current frame with respect to the corresponding background:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "curr_frame = video.frames[400]\n",
    "curr_frame.apply_change_detection(curr_background, 37, distance_euclidean)\n",
    "curr_frame.show(['subtraction', 'mask_raw'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2. Binary Morphology"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We then use binary morphology operators:\n",
    "- 3x3 Opening to remove the noise\n",
    "- 5x5 Closing \n",
    "- 40x3 Opening "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "curr_frame.apply_morphology_operators(MorphOpsSet(\n",
    "    MorphOp(cv2.MORPH_OPEN, (3,3))\n",
    "))\n",
    "plt.subplot(1, 3, 1)\n",
    "curr_frame.show('mask_refined', show=False)\n",
    "\n",
    "curr_frame.apply_morphology_operators(MorphOpsSet(\n",
    "    MorphOp(cv2.MORPH_OPEN, (3,3)),\n",
    "    MorphOp(cv2.MORPH_CLOSE, (5,5), iterations=3)\n",
    "))\n",
    "plt.subplot(1, 3, 2)\n",
    "curr_frame.show('mask_refined', show=False)\n",
    "\n",
    "curr_frame.apply_morphology_operators(MorphOpsSet(\n",
    "    MorphOp(cv2.MORPH_OPEN, (3,3)),\n",
    "    MorphOp(cv2.MORPH_CLOSE, (5,5), iterations=3),\n",
    "    MorphOp(cv2.MORPH_CLOSE, (40,3))\n",
    "))\n",
    "plt.subplot(1, 3, 3)\n",
    "curr_frame.show('mask_refined', show=False)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Blob Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.1. Blob Labeling\n",
    "\n",
    "The labeling of the obtained image is performed using the `cv2.connectedComponents` function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "curr_frame.apply_blob_analysis([])\n",
    "curr_frame.show('blobs_filled')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2. Selected Features\n",
    "\n",
    "The meaningful features considered are:\n",
    "- Area\n",
    "- Perimeter\n",
    "- Barycentre"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.3. Blob Similarity\n",
    "It is necessary to keep continuity between the blob labeling in subsequential frames, therefore, a dissimilarity function is computed to seek for correspondances between the current and previous blobs.\n",
    "The blobs are displayed with the label printed on their barycentre.\n",
    "\n",
    "The function is defined as: TODO\n",
    "\n",
    "The dissimilarity function holds a threshold parameter to define an upper bound for a maximum dissimilarity above which two blobs are always considered different.\n",
    "\n",
    "TODO: Mostrare dissimilarity tra tutti gli oggetti per dare un'idea della media?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_bag = ParameterList({\n",
    "    \"input_video\": \"rilevamento-intrusioni-video.avi\",\n",
    "    \"output_directory\": \"output\",\n",
    "    \"threshold\": [37],\n",
    "    \"distance\": [distance_euclidean],\n",
    "    \"morph_ops\": [\n",
    "        MorphOpsSet(MorphOp(cv2.MORPH_OPEN, (3,3)), MorphOp(cv2.MORPH_CLOSE, (5,5), iterations=3), MorphOp(cv2.MORPH_CLOSE, (40,3)))#MorphOp(cv2.MORPH_CLOSE, (10,3), iterations=3))\n",
    "    ],\n",
    "    \"background_threshold\": [37],\n",
    "    \"background_distance\": [distance_euclidean],\n",
    "    \"background_morph_ops\": [\n",
    "        MorphOpsSet(MorphOp(cv2.MORPH_CLOSE, (3,3), iterations=1),MorphOp(cv2.MORPH_OPEN, (3,3), iterations=2), MorphOp(cv2.MORPH_DILATE, (25,10)), MorphOp(cv2.MORPH_ERODE, (15,5)))\n",
    "    ],\n",
    "    \"alpha\": [0.1],\n",
    "    \"background\": {\n",
    "        \"frames\": [100],\n",
    "        \"interpolation\": [np.median]\n",
    "    }\n",
    "})\n",
    "\n",
    "for p in param_bag:\n",
    "    params = p\n",
    "\n",
    "prev_frame = video.frames[399]\n",
    "prev_frame.intrusion_detection(selective_backgrounds[399], params, [])\n",
    "\n",
    "curr_frame.apply_blob_analysis(prev_frame.blobs)\n",
    "#TODO curr_frame.apply_blob_labeling(dissimilarity_threshold)\n",
    "#TODO curr_frame.show('blobs_labeled\n",
    "plt.subplot(1, 2, 1)\n",
    "prev_frame.show('blobs_filled', show=False)\n",
    "plt.subplot(1, 2, 2)\n",
    "curr_frame.show('blobs_filled', show=False)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.4. Classification \n",
    "To classify the blobs, a function of their features is computed.\n",
    "The function is defined as: TODO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TODO curr_frame.apply_classification(classification_threshold)\n",
    "#TODO curr_frame.show('blobs_classified')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. True/False Object Recognition\n",
    "\n",
    "To apply the object recognition the selected approach is the evaluation of the edges strength, such that, when the contours of a found blob presents sharp edges in the original image, it is considered to be present, otherwise it is labeled as fake.\n",
    "\n",
    "The computation is performed by using a Sobel operator returning a smoothed edge score not taking into account the large amount of noise present in the original frame. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TODO curr_frame.apply_object_recognition(recognition_threshold)\n",
    "#TODO curr_frame.show('blobs_refined')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Output Generation\n",
    "\n",
    "### 6.1. Text Output\n",
    "\n",
    "A CSV file is then generated, for each frame the following informations are stored:\n",
    "- Frame Index\n",
    "- Number of Detected Objects\n",
    "- Then a row for each detected object is printed listing this features:\n",
    "   - Object Label\n",
    "   - Area\n",
    "   - Perimeter\n",
    "   - Classification\n",
    "\n",
    "### 6.2. Video Output\n",
    "\n",
    "The graphical output shows the contours of the found objects, the color of the contour depends on the object classification:\n",
    "- Person: Blue\n",
    "- True Object: Green\n",
    "- Fake Object: Red"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "curr_frame.show('blobs_contours')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
